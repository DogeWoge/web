#!/usr/bin/env python

import os
import shutil
import subprocess
import sys

import git
import urllib


SITE_URL = 'https://eyqs.ca'
REPO_REMOTE = 'origin'
BUILD_BRANCH = 'gh-pages'
SITE_TITLE = 'Eugene Y. Q. Shen'

REPO_ROOT = '/home/eyqs/Downloads/Dropbox/Projects/web/'
POSTS_FOLDER = '_posts'
LAYOUTS_FOLDER = '_layouts'
INCLUDES_FOLDER = '_includes'
BUILD_FOLDER = '_site'
BLOGS_FOLDER = 'blogs'
ASSETS_FOLDER = 'assets'
SCRIPT_FILE = 'web'
DEFAULT_FILE = 'index.html'
BUILD_PATH = os.path.join(REPO_ROOT, BUILD_FOLDER)
INDEX_PATH = os.path.join(REPO_ROOT, DEFAULT_FILE)

PREAMBLE_SEPARATOR = '---\n'
IGNORED_FILES = ['.git', '.gitignore', '.gitmodules', 'web',
        'LICENSE.md', 'README.md', 'requirements.txt', ASSETS_FOLDER,
        POSTS_FOLDER, LAYOUTS_FOLDER, INCLUDES_FOLDER, BUILD_FOLDER]
CONTENT_EXTENSIONS = ['.html', '.md']
SPECIAL_FILES = [DEFAULT_FILE, '404.html']
SPECIAL_KEYS = ['content', 'head_title', 'site_title', 'url']



def mkdir(*args):
    directory = os.path.join(*args)
    if not os.path.exists(directory):
        os.mkdir(directory)


def get_name(name):
    return os.path.splitext(name)[0]


def get_extension(name):
    return os.path.splitext(name)[1]


def is_content(name):
    return get_extension(name) in CONTENT_EXTENSIONS


def is_include(line):
    strip = line.strip()
    return strip.startswith('{% include ') and strip.endswith('.html %}')


def get_include(line):
    return line.strip().split()[2]


def has_tag(line):
    return '{{' in line and '}}' in line


def get_tag(line):
    start = line.index('{{')
    end = line.index('}}')
    return line[start+2:end].strip()


def replace_tag(line, value):
    start = line.index('{{')
    end = line.index('}}')
    return line.replace(line[start:end+2], value)


def generate(src_path, dest_path, page_url):

    before_tag = []
    content = []
    preamble = None
    parameters = {}

    with open(src_path, 'r') as infile:
        for line in infile:
            if preamble and line == PREAMBLE_SEPARATOR:
                preamble = False
                continue
            if preamble:
                key, value = line.split(':', 1)
                if key in SPECIAL_KEYS:
                    raise ValueError(
                            f'must not use "{key}" as key in {src_path}')
                parameters[key] = value.strip()
            if preamble is None and line == PREAMBLE_SEPARATOR:
                preamble = True
            if not preamble:
                content.append(line)

    if 'layout' not in parameters:
        raise ValueError(f'must have "layout" as key in {src_path}')

    parameters['site_title'] = SITE_TITLE
    if 'title' in parameters and src_path != INDEX_PATH:
        parameters['head_title'] = f'{parameters["title"]} - {SITE_TITLE}'
    else:
        parameters['head_title'] = SITE_TITLE
    if src_path == INDEX_PATH:
        parameters['url'] = f'{SITE_URL}/'
    else:
        parameters['url'] = f'{SITE_URL}/{page_url}'

    layout_path = os.path.join(
            REPO_ROOT, LAYOUTS_FOLDER, f'{parameters["layout"]}.html')
    with open(layout_path, 'r') as layoutfile:
        for line in layoutfile:
            indent = line.split('{', 1)[0]

            if is_include(line):
                include_path = os.path.join(
                        REPO_ROOT, INCLUDES_FOLDER, get_include(line))
                with open(include_path, 'r') as includefile:
                    for includeline in includefile:
                        before_tag.append(indent + includeline)
            elif has_tag(line) and get_tag(line) == 'content':
                for contentline in content:
                    before_tag.append(indent + contentline)
            else:
                before_tag.append(line)

    before_url = []
    for line in before_tag:
        if has_tag(line):
            key = get_tag(line)
            if key not in parameters:
                print(f'Warning: key "{key}" was not found in {src_path}')
            else:
                before_url.append(replace_tag(line, parameters[key]))
        else:
            before_url.append(line)

    with open(dest_path, 'w') as outfile:
        for line in before_url:
            if line.strip():
                outfile.write(line.replace('"%/', f'"{SITE_URL}/'))
            else:
                outfile.write('\n')



def archive():

    print('Archiving index')
    urllib.request.urlopen(f'http://web.archive.org/save/{SITE_URL}')

    with os.scandir(REPO_ROOT) as it:
        for entry in it:
            if entry.name in UNARCHIVED_FILES:
                continue
            if get_extension(entry.name) == '.html':
                page = get_name(entry.name)
                print(f'Archiving page: {page}')
                urllib.request.urlopen('http://web.archive.org/'
                        + f'save/{SITE_URL}/{page}/')

    with os.scandir(os.path.join(REPO_ROOT, POSTS_FOLDER)) as it:
        for entry in it:
            post = get_name(entry.name)
            print(f'Archiving post: {post}')
            urllib.request.urlopen('http://web.archive.org/'
                    + f'save/{SITE_URL}/{BLOGS_FOLDER}/{post}/')


def push():

    repo = git.Repo(REPO_ROOT)
    repo.git.subtree('push', REPO_REMOTE, BUILD_BRANCH, prefix=BUILD_FOLDER)


def copy_folder(srcfolder='', destfolder=None):

    if destfolder == None:
        destfolder = srcfolder

    mkdir(BUILD_PATH, destfolder)
    with os.scandir(os.path.join(REPO_ROOT, srcfolder)) as it:
        for entry in it:
            if entry.name in IGNORED_FILES:
                continue

            if is_content(entry.name):
                if entry.name in SPECIAL_FILES:
                    dest = os.path.join(BUILD_FOLDER, destfolder,
                            f'{get_name(entry.name)}.html')
                    print('Generating page: ' +
                            f'{os.path.join(srcfolder, entry.name)} -> {dest}')
                    generate(entry.path, os.path.join(REPO_ROOT, dest),
                            f'{destfolder}/{get_name(entry.name)}.html')
                else:
                    dest = os.path.join(BUILD_FOLDER, destfolder,
                            get_name(entry.name), DEFAULT_FILE)
                    print('Generating page: ' +
                            f'{os.path.join(srcfolder, entry.name)} -> {dest}')
                    mkdir(BUILD_PATH, destfolder, get_name(entry.name))
                    generate(entry.path, os.path.join(REPO_ROOT, dest),
                            f'{destfolder}/{get_name(entry.name)}/')

            else:
                if entry.is_dir():
                    if os.path.exists(os.path.join(entry.path, SCRIPT_FILE)):
                        subprocess.call([
                            'python',
                            os.path.join(entry.path, SCRIPT_FILE),
                            'build',
                        ])
                    copy_folder(f'{os.path.join(srcfolder, entry.name)}/',
                            f'{os.path.join(destfolder, entry.name)}/')

                else:
                    dest = os.path.join(BUILD_FOLDER, destfolder, entry.name)
                    print('Copying file: ' +
                            f'{os.path.join(srcfolder, entry.name)} -> {dest}')
                    shutil.copy(entry.path, os.path.join(REPO_ROOT, dest))


def build():

    if os.path.exists(BUILD_PATH):
        print(f'Removing build directory: {BUILD_FOLDER}/')
        shutil.rmtree(BUILD_PATH)

    copy_folder()
    copy_folder(POSTS_FOLDER, BLOGS_FOLDER)
    print(f'Copying folder: {ASSETS_FOLDER}/ -> {ASSETS_FOLDER}/')
    shutil.copytree(os.path.join(REPO_ROOT, ASSETS_FOLDER),
            os.path.join(BUILD_PATH, ASSETS_FOLDER))



if __name__ == '__main__':

    if len(sys.argv) != 2:
        print('Usage: ./web [archive|build|push]')
        exit(1)

    os.chdir(REPO_ROOT)
    if sys.argv[1] == 'archive':
        archive()
    elif sys.argv[1] == 'build':
        build()
    elif sys.argv[1] == 'push':
        push()
    else:
        print('Usage: ./web [archive|build|push]')
        exit(1)
